# =============================================================================
# OrbitOS CI Pipeline - WITH HARD GATES
# =============================================================================
# This workflow runs on every push and pull request to enforce quality gates.
# All checks must pass before merging is allowed.
#
# HARD GATES (will block merge):
# 1. AI Documentation  - Spec files must be complete
# 2. User Manual       - Auto-generated docs must exist
# 3. Testing           - Required test coverage must be met
# 4. Code Quality      - No lint/type errors, security scan passed
#
# Test Coverage:
# - Backend: Unit + Integration tests with code coverage
# - Frontend: Unit tests (Vitest) + E2E tests (Playwright)
# - Docker: Full stack integration tests
# =============================================================================

name: CI

on:
  push:
    branches: [main, develop]
    paths:
      - 'orbitos-api/**'
      - 'orbitos-web/**'
      - 'specs/**'
      - 'contracts/**'
      - '.github/workflows/ci.yml'
  pull_request:
    branches: [main, develop]
    paths:
      - 'orbitos-api/**'
      - 'orbitos-web/**'
      - 'specs/**'
      - 'contracts/**'
      - '.github/workflows/ci.yml'

env:
  DOTNET_VERSION: '8.0.x'
  NODE_VERSION: '20.x'

jobs:
  # ===========================================================================
  # Backend (.NET) Checks
  # ===========================================================================
  backend:
    name: Backend (.NET)
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: orbitos-api

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}

      - name: Restore dependencies
        run: dotnet restore

      - name: Build
        run: dotnet build --configuration Release --no-restore

      - name: Run tests with coverage
        run: |
          dotnet test --configuration Release --no-build \
            --collect:"XPlat Code Coverage" \
            --results-directory ./TestResults \
            -- DataCollectionRunSettings.DataCollectors.DataCollector.Configuration.Format=cobertura

      - name: Check code coverage
        uses: irongut/CodeCoverageSummary@v1.3.0
        with:
          filename: orbitos-api/TestResults/**/coverage.cobertura.xml
          badge: true
          fail_below_min: false  # Set to true once coverage reaches 60%
          format: markdown
          hide_branch_rate: false
          hide_complexity: false
          indicators: true
          output: both
          thresholds: '60 80'  # Target: 60% minimum, 80% goal (currently at ~23%)

      - name: Upload coverage report
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report-backend
          path: orbitos-api/TestResults

  # ===========================================================================
  # Frontend (Nuxt/Vue) Checks
  # ===========================================================================
  frontend:
    name: Frontend (Nuxt)
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: orbitos-web

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: orbitos-web/package-lock.json

      - name: Install dependencies
        run: npm ci --legacy-peer-deps

      - name: Type check
        run: npm run typecheck
        continue-on-error: true  # Track failures but don't block yet

      - name: Lint
        run: npm run lint
        continue-on-error: true  # Track failures but don't block yet

      - name: Run unit tests with coverage
        run: npm run test:unit:coverage
        continue-on-error: true  # Track failures but don't block yet

      - name: Build
        run: npm run build

      - name: Upload frontend coverage
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: coverage-report-frontend
          path: orbitos-web/coverage/

  # ===========================================================================
  # Contract Validation
  # ===========================================================================
  contracts:
    name: Contract Validation
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Validate OpenAPI spec
        run: |
          npm install -g @redocly/cli
          redocly lint contracts/openapi.yaml
        continue-on-error: true  # Track failures but don't block yet

  # ===========================================================================
  # Security Scanning
  # ===========================================================================
  security:
    name: Security Scan
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Check for secrets in code
        run: |
          # Simple secret detection
          if grep -rE "(password|secret|api_key|apikey)\s*[:=]\s*['\"][^'\"]+['\"]" \
            --include="*.cs" --include="*.ts" --include="*.json" \
            --exclude-dir=node_modules --exclude-dir=bin --exclude-dir=obj \
            . 2>/dev/null | grep -v "example\|template\|placeholder\|your-"; then
            echo "::warning::Potential secrets found in code. Please review."
          fi

      - name: .NET security scan
        working-directory: orbitos-api
        run: |
          dotnet list package --vulnerable --include-transitive 2>&1 | tee security-report.txt
          if grep -q "has the following vulnerable packages" security-report.txt; then
            echo "::warning::Vulnerable packages detected. Please review security-report.txt"
          fi

      - name: NPM security scan
        working-directory: orbitos-web
        run: |
          npm audit --audit-level=high || echo "::warning::NPM audit found issues. Please review."

  # ===========================================================================
  # Spec Validation (HARD GATE)
  # ===========================================================================
  specs:
    name: Spec Validation (HARD GATE)
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Validate spec JSON files
        run: |
          # Check that all spec files are valid JSON
          for file in specs/features/*.json specs/entities/*.json; do
            if [ -f "$file" ] && [ "$(basename $file)" != "_template.json" ]; then
              if ! python3 -m json.tool "$file" > /dev/null 2>&1; then
                echo "Invalid JSON: $file"
                exit 1
              fi
            fi
          done
          echo "All spec files are valid JSON"

      - name: Check required spec fields
        run: |
          # Validate feature specs have all required fields
          python3 << 'EOF'
          import json
          import sys
          import os

          REQUIRED_FEATURE_FIELDS = [
              'id', 'name', 'description', 'status', 'capabilities',
              'entities', 'api_endpoints', 'test_coverage'
          ]

          REQUIRED_ENTITY_FIELDS = [
              'id', 'name', 'description', 'fields'
          ]

          errors = []

          # Check features
          features_dir = 'specs/features'
          if os.path.exists(features_dir):
              for f in os.listdir(features_dir):
                  if f.startswith('F') and f.endswith('.json') and not f.startswith('_'):
                      path = os.path.join(features_dir, f)
                      with open(path) as file:
                          data = json.load(file)
                          for field in REQUIRED_FEATURE_FIELDS:
                              if field not in data:
                                  errors.append(f"{f}: Missing required field '{field}'")

          # Check entities
          entities_dir = 'specs/entities'
          if os.path.exists(entities_dir):
              for f in os.listdir(entities_dir):
                  if f.startswith('ENT') and f.endswith('.json') and not f.startswith('_'):
                      path = os.path.join(entities_dir, f)
                      with open(path) as file:
                          data = json.load(file)
                          for field in REQUIRED_ENTITY_FIELDS:
                              if field not in data:
                                  errors.append(f"{f}: Missing required field '{field}'")

          if errors:
              print("SPEC VALIDATION FAILED:")
              for e in errors:
                  print(f"  - {e}")
              sys.exit(1)
          else:
              print("All specs have required fields")
          EOF

      - name: Check feature-entity references
        run: |
          # Verify that entities referenced in features exist
          python3 << 'EOF'
          import json
          import os
          import sys

          errors = []

          # Get all entity IDs
          entity_ids = set()
          entities_dir = 'specs/entities'
          if os.path.exists(entities_dir):
              for f in os.listdir(entities_dir):
                  if f.startswith('ENT') and f.endswith('.json') and not f.startswith('_'):
                      with open(os.path.join(entities_dir, f)) as file:
                          data = json.load(file)
                          entity_ids.add(data.get('id', ''))

          # Check feature references
          features_dir = 'specs/features'
          if os.path.exists(features_dir):
              for f in os.listdir(features_dir):
                  if f.startswith('F') and f.endswith('.json') and not f.startswith('_'):
                      with open(os.path.join(features_dir, f)) as file:
                          data = json.load(file)
                          for entity_ref in data.get('entities', []):
                              if entity_ref not in entity_ids:
                                  errors.append(f"{f}: References non-existent entity '{entity_ref}'")

          if errors:
              print("REFERENCE VALIDATION FAILED:")
              for e in errors:
                  print(f"  - {e}")
              sys.exit(1)
          else:
              print("All entity references are valid")
          EOF

  # ===========================================================================
  # User Manual Generation & Validation (HARD GATE)
  # ===========================================================================
  user-manual:
    name: User Manual (HARD GATE)
    runs-on: ubuntu-latest
    needs: [specs]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Generate user manual from specs
        run: node scripts/generate-user-manual.js

      - name: Validate user manual completeness
        run: |
          python3 << 'EOF'
          import json
          import os
          import sys

          errors = []

          # Check docs/user-manual exists
          manual_dir = 'docs/user-manual'
          if not os.path.exists(manual_dir):
              print("ERROR: docs/user-manual directory not found")
              sys.exit(1)

          # Check features have manuals
          features_dir = 'specs/features'
          manual_features_dir = os.path.join(manual_dir, 'features')

          if os.path.exists(features_dir):
              for f in os.listdir(features_dir):
                  if f.startswith('F') and f.endswith('.json') and not f.startswith('_'):
                      with open(os.path.join(features_dir, f)) as file:
                          data = json.load(file)
                          feature_id = data.get('id')
                          manual_path = os.path.join(manual_features_dir, f"{feature_id}.md")

                          if not os.path.exists(manual_path):
                              errors.append(f"Missing user manual for {feature_id}")
                          else:
                              # Check manual is not empty
                              with open(manual_path) as mf:
                                  content = mf.read()
                                  if len(content) < 200:
                                      errors.append(f"User manual for {feature_id} is too short")

          # Check field-help.json exists
          if not os.path.exists(os.path.join(manual_dir, 'field-help.json')):
              errors.append("Missing field-help.json")

          if errors:
              print("USER MANUAL VALIDATION FAILED:")
              for e in errors:
                  print(f"  - {e}")
              sys.exit(1)
          else:
              print("User manual validation passed")
          EOF

      - name: Upload user manual artifacts
        uses: actions/upload-artifact@v4
        with:
          name: user-manual
          path: docs/user-manual/

  # ===========================================================================
  # Feature Readiness Gate (FINAL HARD GATE)
  # ===========================================================================
  feature-readiness:
    name: Feature Readiness (FINAL GATE)
    runs-on: ubuntu-latest
    needs: [backend, frontend, specs, user-manual, security]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Run feature readiness validation
        run: |
          # Generate user manual first (needed for validation)
          node scripts/generate-user-manual.js

          # Run the full readiness check
          node scripts/validate-feature-readiness.js

      - name: Check all gates passed
        run: |
          echo "## Feature Readiness Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "All hard gates must pass before features can be marked as ready:" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Gate | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| AI Documentation | ${{ needs.specs.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| User Manual | ${{ needs.user-manual.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Backend Tests | ${{ needs.backend.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Frontend Tests | ${{ needs.frontend.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Security Scan | ${{ needs.security.result }} |" >> $GITHUB_STEP_SUMMARY

  # ===========================================================================
  # E2E Tests (on main branch only)
  # ===========================================================================
  e2e:
    name: E2E Tests
    runs-on: ubuntu-latest
    needs: [backend, frontend]
    if: github.ref == 'refs/heads/main' || github.event_name == 'pull_request'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install Playwright
        working-directory: orbitos-web
        run: |
          npm ci --legacy-peer-deps
          npx playwright install --with-deps chromium

      - name: Run Playwright tests
        working-directory: orbitos-web
        run: npx playwright test --project=chromium
        continue-on-error: true  # Track failures but don't block yet
        env:
          CI: true

      - name: Upload Playwright report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: playwright-report
          path: orbitos-web/playwright-report/
          retention-days: 30

  # ===========================================================================
  # Docker Integration Tests
  # ===========================================================================
  docker-tests:
    name: Docker Integration Tests
    runs-on: ubuntu-latest
    needs: [backend, frontend]
    if: github.ref == 'refs/heads/main'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build API Docker image
        run: |
          docker build -t orbitos-api:test ./orbitos-api

      - name: Build Web Docker image
        run: |
          docker build -t orbitos-web:test ./orbitos-web

      - name: Run Docker Compose tests
        run: |
          docker compose -f docker-compose.test.yml up -d postgres-test
          sleep 10  # Wait for PostgreSQL
          docker compose -f docker-compose.test.yml up -d api-test
          sleep 15  # Wait for API
          # Run API health check
          curl -f http://localhost:5027/health || exit 1
          echo "Docker integration tests passed!"

      - name: Cleanup
        if: always()
        run: docker compose -f docker-compose.test.yml down -v

  # ===========================================================================
  # Build Summary
  # ===========================================================================
  build-summary:
    name: Build Summary
    runs-on: ubuntu-latest
    needs: [backend, frontend, contracts, security, specs, user-manual, feature-readiness, e2e]
    if: always()

    steps:
      - name: Check build status
        run: |
          echo "## Build Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Hard Gates (Must Pass)" >> $GITHUB_STEP_SUMMARY
          echo "| Gate | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| AI Documentation (Specs) | ${{ needs.specs.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| User Manual | ${{ needs.user-manual.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Backend Tests | ${{ needs.backend.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Frontend Tests | ${{ needs.frontend.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Security Scan | ${{ needs.security.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| **Feature Readiness** | **${{ needs.feature-readiness.result }}** |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Additional Checks" >> $GITHUB_STEP_SUMMARY
          echo "| Check | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Contracts | ${{ needs.contracts.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| E2E | ${{ needs.e2e.result }} |" >> $GITHUB_STEP_SUMMARY
